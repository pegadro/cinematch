{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e43240c-870c-4e7f-a9bb-5fb241293cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.datasets import load_datasets, get_matrix_ratings, get_matrix_rated, get_n_users, get_n_movies, normalize_matrix_ratings, load_movies_enhanced\n",
    "import tensorflow as tf\n",
    "from thefuzz import process\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d413c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies_titles = movies[\"title\"]\n",
    "# query = \"memento\"\n",
    "\n",
    "# matches = process.extract(query, movies_titles, limit=5)\n",
    "\n",
    "# for m in matches:\n",
    "#     print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1064b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "\n",
    "class CFRecommender(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_users, n_movies, n_features=200, max_iterations=100, lambda_=1.5, learning_rate=0.1, intercept=True):\n",
    "        self.n_users = n_users\n",
    "        self.n_movies = n_movies\n",
    "        self.n_features = n_features\n",
    "        self.max_iterations = max_iterations\n",
    "        self.lambda_ = lambda_\n",
    "        self.learning_rate = learning_rate\n",
    "        self.intercept = intercept\n",
    "        \n",
    "    def collaborative_filtering_cost(self, X, W, b, Y, R, lambda_):\n",
    "        j = (tf.linalg.matmul(X, tf.transpose(W)) + (b if self.intercept else 0) - Y) * R\n",
    "        J = 0.5 * tf.reduce_sum(j ** 2) + (lambda_ / 2) * (tf.reduce_sum(X ** 2) + tf.reduce_sum(W ** 2))\n",
    "        return J\n",
    "        \n",
    "    def fit(self, Y, R):\n",
    "        tf.random.set_seed(42)\n",
    "\n",
    "        self.W = tf.Variable(tf.random.normal(shape=(self.n_users,  self.n_features), stddev=0.1, dtype=tf.float64),  name='W')\n",
    "        self.X = tf.Variable(tf.random.normal(shape=(self.n_movies, self.n_features), stddev=0.1, dtype=tf.float64),  name='X')\n",
    "        self.b = tf.Variable(tf.random.normal(shape=(1,             self.n_users), stddev=0.1, dtype=tf.float64),  name='b')\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "        \n",
    "        for i in range(self.max_iterations):\n",
    "            with tf.GradientTape() as tape:\n",
    "                cost_value = self.collaborative_filtering_cost(self.X, self.W, self.b, Y, R, self.lambda_)\n",
    "            \n",
    "            if self.intercept:\n",
    "                grads = tape.gradient(cost_value, [self.X,self.W,self.b])\n",
    "                optimizer.apply_gradients(zip(grads, [self.X,self.W,self.b]))\n",
    "            else:\n",
    "                grads = tape.gradient(cost_value, [self.X,self.W])\n",
    "                optimizer.apply_gradients(zip(grads, [self.X,self.W]))\n",
    "        \n",
    "            if i % 20 == 0:\n",
    "                print(f\"Training loss at iteration {i}: {cost_value:0.1f}\")\n",
    "        \n",
    "        return self\n",
    "                \n",
    "    def predict(self):\n",
    "        if self.intercept:\n",
    "            return np.matmul(self.X.numpy(), np.transpose(self.W.numpy())) + self.b\n",
    "        else:\n",
    "            return np.matmul(self.X.numpy(), np.transpose(self.W.numpy()))\n",
    "        \n",
    "    \n",
    "    def score(self, Y, R):\n",
    "        return self.collaborative_filtering_cost(self.X, self.W, self.b, Y, R, self.lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f04614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingsNormalizer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None, R=None):\n",
    "        self.R = R\n",
    "        \n",
    "        self.means_ = np.array([])\n",
    "        \n",
    "        for i in range(R.shape[0]):\n",
    "            indexes = R[i] == 1\n",
    "            self.means_ = np.append(self.means_, X[i][indexes].mean() if indexes.any() else 0)\n",
    "            \n",
    "        return self\n",
    "            \n",
    "    def transform(self, X):\n",
    "        X_mean_normalized = X.copy()\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            if i%100 == 0:\n",
    "                print(i)\n",
    "            \n",
    "            indexes = self.R[i] == 1\n",
    "            X_mean_normalized[i][indexes] -= self.means_[i]\n",
    "            # for j in range(X.shape[1]):\n",
    "            #     if self.R[i,j] == 1:\n",
    "            #         X_mean_normalized[i,j] -= self.means_[i]\n",
    "        \n",
    "        return X_mean_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0227456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "sparse_matrix_ratings = sparse.load_npz('sparse_matrix_ratings.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3957ce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix_ratings_5000 = sparse_matrix_ratings[:,:5000]\n",
    "matrix_ratings_5000 = sparse_matrix_ratings_5000.toarray()\n",
    "matrix_ratings_5000.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e7967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_rated_5000 = get_matrix_rated(matrix_ratings_5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038e7523",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_normalizer = RatingsNormalizer()\n",
    "ratings_normalizer.fit(matrix_ratings_5000, R=matrix_rated_5000)\n",
    "matrix_ratings_5000_norm = ratings_normalizer.transform(matrix_ratings_5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eedd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_movies, n_users = matrix_ratings_5000.shape\n",
    "cf_recommender = CFRecommender(\n",
    "    n_users=n_users,\n",
    "    n_movies=n_movies,\n",
    "    n_features=200,\n",
    "    max_iterations=120,\n",
    "    lambda_=1.5,\n",
    "    learning_rate=0.1,\n",
    "    intercept=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c4e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_recommender.fit(matrix_ratings_5000_norm, matrix_rated_5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e09c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_recommender.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e04eb98-6053-42ee-9fa3-77874b1be457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "links, movies, ratings, tags = load_datasets()\n",
    "n_users = get_n_users(ratings)\n",
    "n_movies = get_n_movies(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61cf020",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = get_matrix_ratings(ratings, movies) # Matrix of ratings\n",
    "R = get_matrix_rated(Y) # Matrix of 1/0 whether the movie was rated or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782473b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ratings = np.zeros(n_movies)\n",
    "\n",
    "my_ratings[0] = 5 # Toy Story\n",
    "my_ratings[5374] = 5 # The incredibles\n",
    "my_ratings[510] = 4.5 # Silence of the Lambs\n",
    "my_ratings[4360] = 4 # Finding nemo\n",
    "my_ratings[2379] = 4.5 # Stuart Little\n",
    "my_ratings[1527] = 4 # The Parent Trap\n",
    "my_ratings[3819] = 5 # Spider-Man (2002)\n",
    "my_ratings[8406] = 4 # The Amazing Spider-Man 2\n",
    "my_ratings[706] = 5 # 2001: A Space Odyssey\n",
    "my_ratings[1691] = 4 # Rush hour\n",
    "\n",
    "my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n",
    "\n",
    "#for i in range(len(my_rated)):\n",
    "#    print(f\"Rated {my_ratings[my_rated[i]]} for {movies.loc[my_rated[i], 'title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2cc084",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.c_[my_ratings, Y] # Add my ratings\n",
    "R = np.c_[(my_ratings != 0).astype(int), R] # Add my indicators to indicator matrix R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d88979",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_normalizer = RatingsNormalizer()\n",
    "ratings_normalizer.fit(Y, R=R)\n",
    "Ynorm = ratings_normalizer.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e5c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_movies, n_users = Y.shape\n",
    "\n",
    "cf_recommender = CFRecommender(\n",
    "    n_users=n_users,\n",
    "    n_movies=n_movies,\n",
    "    n_features=200,\n",
    "    max_iterations=120,\n",
    "    lambda_=1.5,\n",
    "    learning_rate=0.1,\n",
    "    intercept=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb047a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_recommender.fit(Ynorm, R)\n",
    "p = cf_recommender.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b30c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = p + ratings_normalizer.means_[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb88e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_predictions = pm[:,0]\n",
    "\n",
    "ix = tf.argsort(my_predictions, direction='DESCENDING')\n",
    "\n",
    "for i in range(17):\n",
    "    j = ix[i]\n",
    "    if j not in my_rated:\n",
    "        print(f'Predicting rating {my_predictions[j.numpy()]:0.2f} for movie {movies[\"title\"][j.numpy()]} (genres = {movies[\"genres\"][j.numpy()]})')\n",
    "\n",
    "print(\"\\n\\nOriginal vs. Predicted\")\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movies[\"title\"][i]} (genres = {movies[\"genres\"][i]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7b5874",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_enhanced = load_movies_enhanced()\n",
    "filter = (movies_enhanced[\"ratings\"] > 20)\n",
    "movies_enhanced[\"pred\"] = my_predictions\n",
    "\n",
    "movies_enhanced = movies_enhanced.reindex(columns=[\"pred\", \"mean_rating\", \"ratings\", \"title\"])\n",
    "movies_enhanced.loc[ix[:300]].loc[filter].sort_values(\"mean_rating\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4980413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_grid_search(model_class, param_grid, Y, R):\n",
    "    best_model = None\n",
    "    best_score = np.inf\n",
    "    best_params = {}\n",
    "    \n",
    "    from itertools import product\n",
    "    for params in product(*param_grid.values()):\n",
    "        params_dict = dict(zip(param_grid.keys(), params))\n",
    "        model = model_class(n_users=Y.shape[1], n_movies=Y.shape[0], **params_dict)\n",
    "    \n",
    "        model.fit(Y, R)\n",
    "        \n",
    "        score = model.score(Y, R)\n",
    "        \n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "            best_params = params_dict\n",
    "            \n",
    "        print(f\"Tested {params_dict}, Score: {score}\")\n",
    "        \n",
    "    return best_model, best_model, best_params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_features\": [50,100, 150],\n",
    "    \"max_iterations\": [100,150],\n",
    "    \"lambda_\": [1,1.5],\n",
    "    \"learning_rate\": [0.1,0.01],\n",
    "    \"intercept\": [False,True]\n",
    "}\n",
    "\n",
    "best_model, best_score, best_params = custom_grid_search(CFRecommender, param_grid, Ynorm, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'n_features': 150, 'max_iterations': 100, 'lambda_': 1, 'learning_rate': 0.1, 'intercept': True}\n",
    "\n",
    "param_grid = {\n",
    "    \"n_features\": [140, 150, 160],\n",
    "    \"max_iterations\": [90, 100, 110],\n",
    "    \"lambda_\": [1],\n",
    "    \"learning_rate\": [0.1],\n",
    "    \"intercept\": [True]\n",
    "}\n",
    "\n",
    "best_model, best_score, best_params = custom_grid_search(CFRecommender, param_grid, Ynorm, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ff4fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'n_features': 160, 'max_iterations': 110, 'lambda_': 1, 'learning_rate': 0.1, 'intercept': True}\n",
    "param_grid = {\n",
    "    \"n_features\": [160,170,180],\n",
    "    \"max_iterations\": [100, 110, 120],\n",
    "    \"lambda_\": [1],\n",
    "    \"learning_rate\": [0.1],\n",
    "    \"intercept\": [True]\n",
    "}\n",
    "\n",
    "best_model, best_score, best_params = custom_grid_search(CFRecommender, param_grid, Ynorm, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a38f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'n_features': 160, 'max_iterations': 110, 'lambda_': 1, 'learning_rate': 0.1, 'intercept': True}, Score: 3309.7440759128704\n",
    "\n",
    "param_grid = {\n",
    "    \"n_features\": [150,160,170],\n",
    "    \"max_iterations\": [110, 120, 130],\n",
    "    \"lambda_\": [1],\n",
    "    \"learning_rate\": [0.1],\n",
    "    \"intercept\": [True]\n",
    "}\n",
    "\n",
    "best_model, best_score, best_params = custom_grid_search(CFRecommender, param_grid, Ynorm, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1058cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(np.where((ratings_matrix_50000 == 0).all(axis=1))[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
